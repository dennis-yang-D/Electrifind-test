{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error, f1_score\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(torch.nn.Module):\n",
    "    ''' A simple neural network that predicts a rating for a user and item'''\n",
    "    \n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Create user embeddings: These are the latent factors for users \n",
    "        # that capture their preferences in which types of items they prefer.\n",
    "        self.user_factors = torch.nn.Embedding(n_users, n_factors)\n",
    "\n",
    "        # Create item embeddings: These are the latent factors for items \n",
    "        # that reflect what they are at an implicit level\n",
    "        self.item_factors = torch.nn.Embedding(n_items, n_factors)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        # Multiply the user and item embeddings to predict the score\n",
    "        return (self.user_factors(user)*self.item_factors(item)).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data from Canvas or from https://grouplens.org/datasets/movielens/100k/ \n",
    "#\n",
    "# From the README:\n",
    "#\n",
    "# MovieLens data sets were collected by the GroupLens Research Project\n",
    "# at the University of Minnesota.\n",
    "# \n",
    "# This data set consists of:\n",
    "#        * 100,000 ratings (1-5) from 943 users on 1682 movies. \n",
    "#        * Each user has rated at least 20 movies. \n",
    "#        * Simple demographic info for the users (age, gender, occupation, zip)\n",
    "\n",
    "training_user_item_rating_tuples = []\n",
    "users = set()\n",
    "items = set()\n",
    "with open('ml-100k/u.train', 'rt') as f:\n",
    "    for line in f:\n",
    "        cols = line.split()\n",
    "        user = int(cols[0])\n",
    "        item = int(cols[1])\n",
    "        rating = int(cols[2])\n",
    "        training_user_item_rating_tuples.append((user, item, rating))\n",
    "        users.add(user)\n",
    "        items.add(item)\n",
    "        \n",
    "test_user_item_rating_tuples = []\n",
    "with open('ml-100k/u.test', 'rt') as f:\n",
    "    for line in f:\n",
    "        cols = line.split()\n",
    "        user = int(cols[0])\n",
    "        item = int(cols[1])\n",
    "        rating = int(cols[2])\n",
    "        test_user_item_rating_tuples.append((user, item, rating))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_user_item_rating_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x  in training_user_item_rating_tuples if x[0]==7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:yaqd1j8y) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stoic-deluge-12</strong> at: <a href='https://wandb.ai/team-orion/electrifind_fm/runs/yaqd1j8y/workspace' target=\"_blank\">https://wandb.ai/team-orion/electrifind_fm/runs/yaqd1j8y/workspace</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_090043-yaqd1j8y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:yaqd1j8y). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/zim/Interviews/wandb/run-20240401_090217-g1et7rq4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/team-orion/electrifind_fm/runs/g1et7rq4/workspace' target=\"_blank\">copper-waterfall-13</a></strong> to <a href='https://wandb.ai/team-orion/electrifind_fm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/team-orion/electrifind_fm' target=\"_blank\">https://wandb.ai/team-orion/electrifind_fm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/team-orion/electrifind_fm/runs/g1et7rq4/workspace' target=\"_blank\">https://wandb.ai/team-orion/electrifind_fm/runs/g1et7rq4/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "100%|██████████| 244/244 [00:00<00:00, 1395.58it/s]\n",
      "\n",
      "\u001b[A\n",
      "100%|██████████| 244/244 [00:00<00:00, 1714.50it/s]\n",
      "\n",
      "\u001b[A\n",
      "100%|██████████| 244/244 [00:00<00:00, 1776.47it/s]\n",
      "\n",
      "\u001b[A\n",
      "100%|██████████| 244/244 [00:00<00:00, 1768.72it/s]\n",
      "\n",
      "\u001b[A\n",
      "100%|██████████| 244/244 [00:00<00:00, 1760.88it/s]\n",
      "\n",
      "\u001b[A\n",
      "100%|██████████| 244/244 [00:00<00:00, 2054.14it/s]\n",
      "\n",
      "100%|██████████| 244/244 [00:00<00:00, 4093.41it/s]\n",
      "\n",
      "100%|██████████| 244/244 [00:00<00:00, 3974.75it/s]\n",
      "\n",
      "\u001b[A\n",
      "100%|██████████| 244/244 [00:00<00:00, 1702.06it/s]\n",
      "\n",
      "\u001b[A\n",
      "100%|██████████| 244/244 [00:00<00:00, 1723.52it/s]\n",
      "\n",
      "\u001b[A\n",
      "100%|██████████| 244/244 [00:00<00:00, 1628.88it/s]\n",
      "\n",
      "\u001b[A\n",
      "100%|██████████| 244/244 [00:00<00:00, 1804.07it/s]\n",
      "\n",
      "\u001b[A\n",
      "100%|██████████| 244/244 [00:00<00:00, 1742.59it/s]\n",
      "\n",
      "\u001b[A\n",
      "100%|██████████| 244/244 [00:00<00:00, 1839.48it/s]\n",
      "\n",
      "\u001b[A\n",
      "100%|██████████| 244/244 [00:00<00:00, 2142.70it/s]\n",
      "\n",
      "\u001b[A\n",
      "100%|██████████| 244/244 [00:00<00:00, 1779.55it/s]\n",
      "\n",
      "\u001b[A\n",
      "100%|██████████| 244/244 [00:00<00:00, 1759.79it/s]\n",
      "\n",
      "\u001b[A\n",
      "100%|██████████| 244/244 [00:00<00:00, 1756.78it/s]\n",
      "\n",
      "\u001b[A\n",
      "100%|██████████| 244/244 [00:00<00:00, 1816.60it/s]\n",
      "\n",
      "\u001b[A\n",
      "100%|██████████| 244/244 [00:00<00:00, 1742.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▇▅▄▃▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>33.77287</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">copper-waterfall-13</strong> at: <a href='https://wandb.ai/team-orion/electrifind_fm/runs/g1et7rq4/workspace' target=\"_blank\">https://wandb.ai/team-orion/electrifind_fm/runs/g1et7rq4/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_090217-g1et7rq4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We'll create a factorization model with 20-dimensinal latent factors for users and items\n",
    "model = MatrixFactorization(306, 90, n_factors=10)\n",
    "\n",
    "# Use Mean Squared Error (MSE) loss to decide how wrong our predictions are\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "lr = 1e-2\n",
    "\n",
    "# This is stochastic gradient descent\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "wandb.init(\n",
    "    project=\"electrifind_fm\",\n",
    "    config={\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"learning_rate\": lr,\n",
    "        \"architecture\": \"Matrix Factorization\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Tell pytorch we're going to train the model\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    loss_sum = 0\n",
    "\n",
    "    random.shuffle(training_user_item_rating_tuples)\n",
    "\n",
    "    for step, data in enumerate(tqdm(training_user_item_rating_tuples)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Get user, item and rating data and put them in a pytorch Tensor object\n",
    "        rating = Variable(torch.FloatTensor([data[2]]))\n",
    "        user = Variable(torch.LongTensor([data[0]]))\n",
    "        item = Variable(torch.LongTensor([data[1]]))\n",
    "\n",
    "        # Predict the rating. Note that this is *implicitly* calling .forward(user, item)\n",
    "        # The notation seems weird at first, but this was adopt to remind everyone\n",
    "        # that nerural network are themselves _functions_ over their inputs!\n",
    "        prediction = model(user, item)\n",
    "\n",
    "        # The loss function (defined above) figures out how wrong the prediction was\n",
    "        loss = loss_fn(prediction, rating)\n",
    "\n",
    "        # Backpropagate the error in the loss through the network\n",
    "        # to figure out what needs to change\n",
    "        loss.backward()\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "        # Update the weights in the network using our particular optimizer\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % 61 == 0 and step > 0:\n",
    "            wandb.log({\"loss\": loss_sum})\n",
    "            loss_sum = 0\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9157, -0.2126,  0.3072,  0.0800, -0.0550, -1.2706, -0.3423,  0.3854,\n",
       "          0.6266, -0.1453]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.user_factors(torch.LongTensor([233]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4613,  1.2089,  1.5593,  0.4276, -0.1740,  0.5365,  1.8357, -0.4351,\n",
       "         -0.2109,  0.5791]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.item_factors(torch.LongTensor([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0058], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.user_factors(torch.LongTensor([233])) \n",
    " * model.item_factors(torch.LongTensor([1]))).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 61/61 [00:00<00:00, 11767.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# Tell pytorch we're going to evaluate, so don't try to learn\n",
    "model.eval()\n",
    "\n",
    "pred_ratings = []\n",
    "gold_ratings = []\n",
    "for user, item, rating in tqdm(test_user_item_rating_tuples):\n",
    "\n",
    "    # Get user and item and put them in a pytorch Tensor object\n",
    "    user = Variable(torch.LongTensor([user]))\n",
    "    item = Variable(torch.LongTensor([item]))\n",
    "\n",
    "    # Predict the score again\n",
    "    prediction = model(user, item)\n",
    "    \n",
    "    # Get the value as a python float object\n",
    "    prediction = prediction.detach().numpy()[0]\n",
    "    \n",
    "    pred_ratings.append(prediction)\n",
    "    gold_ratings.append(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.076237692674947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zim/.virtualenvs/SI630/lib/python3.11/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(gold_ratings, pred_ratings, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ratings = [round(x) for x in pred_ratings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13114754098360656\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(gold_ratings, pred_ratings, average='micro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
